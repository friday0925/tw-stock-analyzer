import pandas as pd
from datetime import datetime, timedelta
import time
import os
import sys

# Add parent directory to path to ensure imports work
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tw_stock_analyzer import config
from tw_stock_analyzer import data_fetcher
from tw_stock_analyzer import indicators
from tw_stock_analyzer import filters
from tw_stock_analyzer import report
from tw_stock_analyzer import notifier
import yfinance as yf

def get_trading_days(days=30):
    """
    å–å¾—æœ€è¿‘ N å€‹äº¤æ˜“æ—¥ (ç°¡å–®æ¨ç®—ï¼Œé‡åˆ°é€±æœ«è·³éï¼Œå¯¦éš›ä»¥æŠ“åˆ°è³‡æ–™ç‚ºæº–)
    """
    trading_days = []
    current = datetime.now()
    
    while len(trading_days) < days:
        # è·³éé€±æœ«
        if current.weekday() < 5: # 0-4 is Mon-Fri
            date_str = current.strftime("%Y%m%d")
            trading_days.append(date_str)
        current -= timedelta(days=1)
        
    return sorted(trading_days) # ç”±èˆŠåˆ°æ–°

def ensure_data_availability(dates):
    """
    ç¢ºä¿æŒ‡å®šæ—¥æœŸçš„è³‡æ–™éƒ½å·²ä¸‹è¼‰
    """
    print(f"æª¢æŸ¥ {len(dates)} å¤©çš„æ­·å²è³‡æ–™...")
    for date_str in dates:
        if not data_fetcher.check_data_exists(date_str):
            print(f"ä¸‹è¼‰ {date_str} è³‡æ–™...")
            df = data_fetcher.fetch_daily_quotes(date_str)
            if df is not None:
                data_fetcher.save_daily_data(date_str, df)
            else:
                print(f"ç„¡æ³•å–å¾— {date_str} è³‡æ–™ (å¯èƒ½ç‚ºå‡æ—¥)")
        else:
            # print(f"{date_str} è³‡æ–™å·²å­˜åœ¨")
            pass

def main():
    print("=== å•Ÿå‹•å°ç£è‚¡å¸‚åˆ†æå·¥å…· ===")
    
    # 1. æº–å‚™æ—¥æœŸç¯„åœ
    # æˆ‘å€‘éœ€è¦è‡³å°‘ 15 å¤©è¨ˆç®— MAï¼Œ9 å¤©è¨ˆç®— KD (ä½† KD éœ€æ›´å¤šå¤©æ”¶æ–‚)
    # æŠ“å–éå» 45 å¤© (æ‰£é™¤å‡æ—¥ç´„ 30 äº¤æ˜“æ—¥)
    target_days = get_trading_days(45)
    
    # 2. ç¢ºä¿è³‡æ–™å­˜åœ¨
    ensure_data_availability(target_days)
    
    # 3. è¼‰å…¥è³‡æ–™ä¸¦åˆä½µ
    all_dfs = []
    for date_str in target_days:
        df = data_fetcher.load_daily_data(date_str)
        if df is not None:
            df['Date'] = date_str
            all_dfs.append(df)
            
    if not all_dfs:
        print("æ²’æœ‰è¶³å¤ çš„è³‡æ–™é€²è¡Œåˆ†æ")
        return
        
    print("åˆä½µè³‡æ–™ä¸­...")
    full_df = pd.concat(all_dfs, ignore_index=True)
    
    # 4. é‡å°æ¯æª”è‚¡ç¥¨è¨ˆç®—æŒ‡æ¨™
    print("è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (MA15, KD)...")
    
    # ç‚ºäº†åŠ é€Ÿï¼Œæˆ‘å€‘åªè™•ç†ä»Šå¤©æœ‰è³‡æ–™çš„è‚¡ç¥¨
    today_date = target_days[-1]
    today_df = all_dfs[-1]
    
    # å–å¾—æ‰€æœ‰è‚¡ç¥¨ä»£è™Ÿ
    codes = full_df['è­‰åˆ¸ä»£è™Ÿ'].unique()
    
    processed_rows = []
    
    # é€™è£¡å¯ä»¥ç”¨ groupby åŠ é€Ÿï¼Œä½†ç‚ºäº†é‚è¼¯æ¸…æ™°ï¼Œå…ˆç”¨ groupby apply
    # Group by Code
    grouped = full_df.groupby('è­‰åˆ¸ä»£è™Ÿ')
    
    # è¨ˆç®—æŒ‡æ¨™
    # æ³¨æ„: é€™è£¡æœƒæ¯”è¼ƒæ…¢ï¼Œå› ç‚ºæœ‰ä¸Šåƒæª”è‚¡ç¥¨
    # å„ªåŒ–: å‘é‡åŒ–è¨ˆç®—
    
    def process_group(group):
        # æ’åº
        group = group.sort_values('Date')
        
        # è¨ˆç®— MA15 Volume (ä¸å«ä»Šæ—¥çš„ 15 æ—¥å¹³å‡ï¼Œç”¨æ–¼æ¯”è¼ƒ)
        # é¡Œç›®: "ç•¶æ—¥æˆäº¤é‡ > éå»15æ—¥å¹³å‡é‡"
        # æˆ‘å€‘è¨ˆç®— rolling meanï¼Œç„¶å¾Œ shift 1
        group['MA15_Vol'] = indicators.calculate_ma_volume(group, days=15).shift(1)
        
        # è¨ˆç®—éå» 15 æ—¥æœ€é«˜åƒ¹ (ä¸å«ä»Šæ—¥)
        # æ¢ä»¶: ç•¶æ—¥è‚¡ç¥¨å¿…é ˆå¤§æ–¼éå»15æ—¥çš„æœ€é«˜åƒ¹
        group['Max15_High'] = group['æœ€é«˜åƒ¹'].rolling(window=15).max().shift(1)
        
        # è¨ˆç®— KD
        group = indicators.calculate_kd(group)
        
        # Stage 1 ä¸è¨ˆç®— MACD (å› ç‚ºå¤©æ•¸ä¸è¶³)
        # group = indicators.calculate_macd(group)
        # group['OSC_Prev'] = group['OSC'].shift(1)
        
        # åªå›å‚³æœ€å¾Œä¸€å¤© (ä¹Ÿå°±æ˜¯ä»Šå¤©)
        return group.iloc[[-1]]

    # æ‡‰ç”¨è¨ˆç®—
    print("æ­£åœ¨è™•ç†å„è‚¡æŒ‡æ¨™ (é€™å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“)...")
    result_df = grouped.apply(process_group)
    
    # Reset index
    result_df = result_df.reset_index(drop=True)
    
    # 5. ç¯©é¸
    print("åŸ·è¡Œç¯©é¸æ¢ä»¶...")
    # æº–å‚™ MA Volume Series (å…¶å¯¦å·²ç¶“åœ¨ result_df è£¡äº†ï¼Œå¯ä»¥ç›´æ¥ç”¨)
    # ä½†æˆ‘å€‘çš„ filter_stocks ä»‹é¢è¨­è¨ˆæ˜¯åˆ†é–‹çš„ï¼Œé€™è£¡èª¿æ•´ä¸€ä¸‹
    # ç‚ºäº†æ–¹ä¾¿ï¼Œæˆ‘å€‘ç›´æ¥åœ¨ result_df ä¸Šç¯©é¸ï¼Œæˆ–è€…ä¿®æ”¹ filter_stocks
    
    # è®“æˆ‘å€‘ä¿®æ”¹ filter_stocks çš„å‘¼å«æ–¹å¼ï¼Œæˆ–è€…ç›´æ¥åœ¨é€™è£¡ç¯©é¸
    # ç‚ºäº†ä¿æŒæ¨¡çµ„åŒ–ï¼Œæˆ‘å€‘å°‡ result_df è½‰ç‚º filter_stocks éœ€è¦çš„æ ¼å¼
    # ä½† filter_stocks åŸæœ¬è¨­è¨ˆæ˜¯æ¥æ”¶ç•¶æ—¥ df å’Œ ma_series
    # ç¾åœ¨ result_df å·²ç¶“åŒ…å« MA15_Vol, K, D
    
    # ç›´æ¥ç¯©é¸
    final_candidates = []
    
    vol_col = 'æˆäº¤è‚¡æ•¸' # éœ€ç¢ºèª data_fetcher æ¸…ç†å¾Œçš„æ¬„ä½åç¨±
    # data_fetcher æ¸…ç†å¾Œï¼Œæ¬„ä½åç¨±ä¸è®Šï¼Œä½†å‹æ…‹è®Šäº†
    # TWSE JSON æ¬„ä½é€šå¸¸æ˜¯ "æˆäº¤è‚¡æ•¸", "é–‹ç›¤åƒ¹", "æœ€é«˜åƒ¹", "æœ€ä½åƒ¹", "æ”¶ç›¤åƒ¹"
    
    for idx, row in result_df.iterrows():
        try:
            # æ¢ä»¶ 1: æˆäº¤é‡ > MA15
            vol = row.get('æˆäº¤è‚¡æ•¸', 0)
            ma_vol = row.get('MA15_Vol', 0)
            
            if pd.isna(ma_vol) or vol <= ma_vol:
                continue
            
            # å„ªåŒ–: æ’é™¤æ¬Šè­‰ (6ä½æ•¸ä»£è™Ÿ ä¸” åç¨±å« è³¼/å”®/ç‰›/ç†Š)
            stock_code = str(row.get('è­‰åˆ¸ä»£è™Ÿ', '')).strip()
            stock_name = str(row.get('è­‰åˆ¸åç¨±', '')).strip()
            
            if len(stock_code) == 6 and any(k in stock_name for k in ["è³¼", "å”®", "ç‰›", "ç†Š"]):
                continue
                
            # æ¢ä»¶ 2: é–‹ç›¤ < æ”¶ç›¤
            open_p = row.get('é–‹ç›¤åƒ¹', 0)
            close_p = row.get('æ”¶ç›¤åƒ¹', 0)
            
            if open_p >= close_p:
                continue
                
            # æ¢ä»¶ 4: æ”¶ç›¤åƒ¹ > éå» 15 æ—¥æœ€é«˜åƒ¹
            max_15_high = row.get('Max15_High', 0)
            if pd.isna(max_15_high) or close_p <= max_15_high:
                continue

            # æ¢ä»¶ 5: æˆäº¤ç­†æ•¸ < 300
            trans_count = row.get('æˆäº¤ç­†æ•¸', 0)
            if pd.isna(trans_count) or trans_count >= 300:
                continue
                
            # æ¢ä»¶ 3: K > D
            k = row.get('K', 0)
            d = row.get('D', 0)
            
            if k <= d:
                continue
                
            # Stage 2: MACD OSC ç¿»ç´… (ä½¿ç”¨ yfinance æŠ“å–é•·å¤©æœŸè³‡æ–™)
            print(f"[{stock_code} {stock_name}] é€šéåˆç¯©ï¼Œæ­£åœ¨æŠ“å–æ­·å²è³‡æ–™é©—è­‰ MACD...")
            try:
                # æŠ“å– 6 å€‹æœˆè³‡æ–™
                yf_ticker = f"{stock_code}.TW"
                hist = yf.download(yf_ticker, period="6mo", progress=False)
                
                if hist.empty or len(hist) < 30:
                    print(f"  ç„¡æ³•å–å¾— {yf_ticker} è¶³å¤ è³‡æ–™ï¼Œè·³é")
                    continue
                    
                # Flatten MultiIndex if present (yfinance update)
                if isinstance(hist.columns, pd.MultiIndex):
                    hist.columns = hist.columns.droplevel(1)
                    
                # è¨ˆç®— MACD
                hist = indicators.calculate_macd(hist)
                
                # å–å¾—æœ€å¾Œå…©ç­†æœ‰æ•ˆè³‡æ–™
                # æ³¨æ„: yfinance æœ€è¿‘ä¸€å¤©å¯èƒ½æ˜¯ä»Šå¤© (å¦‚æœå·²æ”¶ç›¤)
                # æˆ‘å€‘éœ€è¦ç¢ºèªæ—¥æœŸæ˜¯å¦å°æ‡‰
                
                # ç°¡å–®èµ·è¦‹ï¼Œæˆ‘å€‘çœ‹æœ€å¾Œå…©ç­† (å‡è¨­ yfinance å·²æ›´æ–°åˆ°ä»Šå¤©)
                # è‹¥ yfinance é‚„æ²’æ›´æ–°åˆ°ä»Šå¤©ï¼Œé‚£å¯èƒ½æœƒç”¨åˆ°æ˜¨å¤©çš„è³‡æ–™ï¼Œé€™æ˜¯ä¸€å€‹é¢¨éšª
                # ä½†é€šå¸¸å°è‚¡æ”¶ç›¤å¾Œ yfinance æœƒæ›´æ–°
                
                last_row = hist.iloc[-1]
                prev_row = hist.iloc[-2]
                
                osc = last_row['OSC']
                osc_prev = prev_row['OSC']
                
                # print(f"  OSC: {osc:.4f}, Prev: {osc_prev:.4f}")
                
                if pd.isna(osc) or pd.isna(osc_prev):
                    continue
                    
                if not (osc_prev <= 0 and osc > 0):
                    # print("  MACD æ¢ä»¶ä¸ç¬¦")
                    continue
                    
                # æŠŠ MACD æ•¸å€¼å¯«å› row (é¸å¡«ï¼Œç‚ºäº†å ±å‘Šé¡¯ç¤º)
                row['OSC'] = osc
                row['OSC_Prev'] = osc_prev
                
            except Exception as e:
                print(f"  é©—è­‰å¤±æ•—: {e}")
                continue
                
            final_candidates.append(row)
            
        except Exception as e:
            continue
            
    final_df = pd.DataFrame(final_candidates)
    print(f"ç¯©é¸å®Œæˆï¼Œå…± {len(final_df)} æª”ç¬¦åˆæ¢ä»¶")
    
    # 6. ç”¢å‡ºå ±è¡¨
    if not final_df.empty:
        report_path = report.generate_excel(final_df, today_date)
        
        # 7. ç™¼é€é€šçŸ¥
        if report_path:
            msg = f"ğŸ“Š è‚¡å¸‚åˆ†æå ±å‘Š ({today_date})\nç¬¦åˆç¯©é¸æ¢ä»¶: {len(final_df)} æª”"
            notifier.send_telegram_report(report_path, msg)
    else:
        print("ç„¡ç¬¦åˆæ¢ä»¶è‚¡ç¥¨ï¼Œä¸ç™¼é€å ±å‘Š")

if __name__ == "__main__":
    main()
