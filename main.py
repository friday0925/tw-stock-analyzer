import pandas as pd
from datetime import datetime, timedelta
import time
import os
import concurrent.futures
import sys


# Add parent directory to path to ensure imports work
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tw_stock_analyzer import config
from tw_stock_analyzer import data_fetcher
from tw_stock_analyzer import indicators
from tw_stock_analyzer import filters
from tw_stock_analyzer import report
from tw_stock_analyzer import notifier

def get_trading_days(days=30):
    """
    å–å¾—æœ€è¿‘ N å€‹äº¤æ˜“æ—¥ (ç°¡å–®æ¨ç®—ï¼Œé‡åˆ°é€±æœ«è·³éï¼Œå¯¦éš›ä»¥æŠ“åˆ°è³‡æ–™ç‚ºæº–)
    """
    trading_days = []
    current = datetime.now()
    
    while len(trading_days) < days:
        # è·³éé€±æœ«
        if current.weekday() < 5: # 0-4 is Mon-Fri
            date_str = current.strftime("%Y%m%d")
            trading_days.append(date_str)
        current -= timedelta(days=1)
        
    return sorted(trading_days) # ç”±èˆŠåˆ°æ–°

def ensure_data_availability(dates):
    """
    ç¢ºä¿æŒ‡å®šæ—¥æœŸçš„è³‡æ–™éƒ½å·²ä¸‹è¼‰ (å¹³è¡Œä¸‹è¼‰)
    """
    print(f"æª¢æŸ¥ {len(dates)} å¤©çš„æ­·å²è³‡æ–™...")
    
    dates_to_download = []
    
    # Check what needs to be downloaded
    for date_str in dates:
        if not data_fetcher.check_data_exists(date_str):
            dates_to_download.append(date_str)
            
    if not dates_to_download:
        return

    print(f"éœ€è¦ä¸‹è¼‰ {len(dates_to_download)} å¤©çš„è³‡æ–™: {dates_to_download}")
    
    def download_task(date_str):
        print(f"ä¸‹è¼‰ {date_str} è³‡æ–™...")
        try:
            df = data_fetcher.fetch_daily_quotes(date_str)
            if df is not None:
                data_fetcher.save_daily_data(date_str, df)
                return True
            else:
                print(f"ç„¡æ³•å–å¾— {date_str} è³‡æ–™ (å¯èƒ½ç‚ºå‡æ—¥)")
                return False
        except Exception as e:
            print(f"ä¸‹è¼‰å¤±æ•— {date_str}: {e}")
            return False

    # å¹³è¡Œä¸‹è¼‰
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        executor.map(download_task, dates_to_download)


def main():
    print("=== å•Ÿå‹•å°ç£è‚¡å¸‚åˆ†æå·¥å…· ===")
    
    # 1. æº–å‚™æ—¥æœŸç¯„åœ
    # æˆ‘å€‘éœ€è¦è‡³å°‘ 15 å¤©è¨ˆç®— MAï¼Œ9 å¤©è¨ˆç®— KD (ä½† KD éœ€æ›´å¤šå¤©æ”¶æ–‚)
    # æŠ“å–éå» 45 å¤© (æ‰£é™¤å‡æ—¥ç´„ 30 äº¤æ˜“æ—¥)
    target_days = get_trading_days(45)
    
    # 2. ç¢ºä¿è³‡æ–™å­˜åœ¨
    ensure_data_availability(target_days)
    
    # 3. è¼‰å…¥è³‡æ–™ä¸¦åˆä½µ
    all_dfs = []
    for date_str in target_days:
        df = data_fetcher.load_daily_data(date_str)
        if df is not None:
            df['Date'] = date_str
            all_dfs.append(df)
            
    if not all_dfs:
        print("æ²’æœ‰è¶³å¤ çš„è³‡æ–™é€²è¡Œåˆ†æ")
        return
        
    print("åˆä½µè³‡æ–™ä¸­...")
    full_df = pd.concat(all_dfs, ignore_index=True)
    
    # 4. é‡å°æ¯æª”è‚¡ç¥¨è¨ˆç®—æŒ‡æ¨™
    print("è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (Vectorized MA15, KD)...")
    
    # ç‚ºäº†åŠ é€Ÿï¼Œæˆ‘å€‘åªè™•ç†ä»Šå¤©æœ‰è³‡æ–™çš„è‚¡ç¥¨
    today_date = target_days[-1]
    
    # ç¢ºä¿æŒ‰ç…§ Code, Date æ’åº
    full_df = full_df.sort_values(['è­‰åˆ¸ä»£è™Ÿ', 'Date'])
    
    # è¨­å®š Index æ–¹ä¾¿ rolling
    # full_df.set_index('Date', inplace=True) # ä¸é€™éº¼åšï¼Œå› ç‚ºæˆ‘å€‘éœ€è¦ Date column
    
    # GroupBy object
    g = full_df.groupby('è­‰åˆ¸ä»£è™Ÿ')
    
    print("  - è¨ˆç®— MA15 Volume...")
    # é¡Œç›®: "ç•¶æ—¥æˆäº¤é‡ > éå»15æ—¥å¹³å‡é‡" (ä¸å«ç•¶æ—¥)
    # shift(1) å°‡ç•¶æ—¥è®Šæˆæ˜¨æ—¥
    full_df['MA15_Vol'] = g['æˆäº¤è‚¡æ•¸'].transform(lambda x: x.rolling(window=15).mean().shift(1))
    
    print("  - è¨ˆç®— Max15 High...")
    # é¡Œç›®: "ç•¶æ—¥ > éå»15æ—¥æœ€é«˜"
    full_df['Max15_High'] = g['æœ€é«˜åƒ¹'].transform(lambda x: x.rolling(window=15).max().shift(1))
    
    print("  - è¨ˆç®— KD...")
    # è¨ˆç®— RSV
    # RSV = (Close - Min9) / (Max9 - Min9) * 100
    rsv_min = g['æœ€ä½åƒ¹'].transform(lambda x: x.rolling(window=9).min())
    rsv_max = g['æœ€é«˜åƒ¹'].transform(lambda x: x.rolling(window=9).max())
    
    rsv = (full_df['æ”¶ç›¤åƒ¹'] - rsv_min) / (rsv_max - rsv_min) * 100
    full_df['RSV'] = rsv.fillna(50)
    
    # Vectorized KD using groupby().ewm()
    # Pandas 1.2+ supports groupby().ewm()
    # K = EMA(RSV, alpha=1/3)
    # D = EMA(K, alpha=1/3)
    
    print("  - Vectorized EWM...")
    # NOTE: ewm() on groupby returns a DataFrame/Series with multi-index (Code, OriginalIndex) or similar
    # We need to ensure alignment.
    
    # Using transform with ewm is safer to align with original df
    # But transform doesn't support ewm directly in older pandas versions?
    # New pandas: g['RSV'].ewm(...).mean() works and returns MultiIndex.
    # We can assign directly if we sort properly (which we did).
    
    # This returns series with MultiIndex (Code, Index)
    # Re-create groupby or access directly because 'RSV' was added after 'g' was created
    k_series = full_df.groupby('è­‰åˆ¸ä»£è™Ÿ')['RSV'].ewm(alpha=1/3, adjust=False, min_periods=0).mean()
    
    # We need to drop the 'Code' level of index to align with full_df
    # The result index is (è­‰åˆ¸ä»£è™Ÿ, original_index) if as_index=True (default for groupby)
    # But actually ewm() on groupby preserves structure.
    # Let's verify index. k_series index should be compatible if we reset level 0.
    
    full_df['K'] = k_series.reset_index(level=0, drop=True)
    full_df['D'] = full_df.groupby('è­‰åˆ¸ä»£è™Ÿ')['K'].ewm(alpha=1/3, adjust=False, min_periods=0).mean().reset_index(level=0, drop=True)
    
    # ç¯©é¸åªä¿ç•™ä»Šå¤©çš„è³‡æ–™
    print("å–æœ€å¾Œä¸€å¤©è³‡æ–™...")
    result_df = full_df[full_df['Date'] == today_date].copy()

    
    # 5. ç¯©é¸
    print("åŸ·è¡Œç¯©é¸æ¢ä»¶...")
    # æº–å‚™ MA Volume Series (å…¶å¯¦å·²ç¶“åœ¨ result_df è£¡äº†ï¼Œå¯ä»¥ç›´æ¥ç”¨)
    # ä½†æˆ‘å€‘çš„ filter_stocks ä»‹é¢è¨­è¨ˆæ˜¯åˆ†é–‹çš„ï¼Œé€™è£¡èª¿æ•´ä¸€ä¸‹
    # ç‚ºäº†æ–¹ä¾¿ï¼Œæˆ‘å€‘ç›´æ¥åœ¨ result_df ä¸Šç¯©é¸ï¼Œæˆ–è€…ä¿®æ”¹ filter_stocks
    
    # è®“æˆ‘å€‘ä¿®æ”¹ filter_stocks çš„å‘¼å«æ–¹å¼ï¼Œæˆ–è€…ç›´æ¥åœ¨é€™è£¡ç¯©é¸
    # ç‚ºäº†ä¿æŒæ¨¡çµ„åŒ–ï¼Œæˆ‘å€‘å°‡ result_df è½‰ç‚º filter_stocks éœ€è¦çš„æ ¼å¼
    # ä½† filter_stocks åŸæœ¬è¨­è¨ˆæ˜¯æ¥æ”¶ç•¶æ—¥ df å’Œ ma_series
    # ç¾åœ¨ result_df å·²ç¶“åŒ…å« MA15_Vol, K, D
    
    # ç›´æ¥ç¯©é¸
    final_candidates = []
    
    vol_col = 'æˆäº¤è‚¡æ•¸' # éœ€ç¢ºèª data_fetcher æ¸…ç†å¾Œçš„æ¬„ä½åç¨±
    # data_fetcher æ¸…ç†å¾Œï¼Œæ¬„ä½åç¨±ä¸è®Šï¼Œä½†å‹æ…‹è®Šäº†
    # TWSE JSON æ¬„ä½é€šå¸¸æ˜¯ "æˆäº¤è‚¡æ•¸", "é–‹ç›¤åƒ¹", "æœ€é«˜åƒ¹", "æœ€ä½åƒ¹", "æ”¶ç›¤åƒ¹"
    
    for idx, row in result_df.iterrows():
        try:
            # æ¢ä»¶ 1: æˆäº¤é‡ > MA15
            vol = row.get('æˆäº¤è‚¡æ•¸', 0)
            ma_vol = row.get('MA15_Vol', 0)
            
            if pd.isna(ma_vol) or vol <= ma_vol:
                continue
            
            # å„ªåŒ–: æ’é™¤æ¬Šè­‰ (6ä½æ•¸ä»£è™Ÿ ä¸” åç¨±å« è³¼/å”®/ç‰›/ç†Š)
            stock_code = str(row.get('è­‰åˆ¸ä»£è™Ÿ', '')).strip()
            stock_name = str(row.get('è­‰åˆ¸åç¨±', '')).strip()
            
            if len(stock_code) == 6 and any(k in stock_name for k in ["è³¼", "å”®", "ç‰›", "ç†Š"]):
                continue
                
            # æ¢ä»¶ 2: é–‹ç›¤ < æ”¶ç›¤
            open_p = row.get('é–‹ç›¤åƒ¹', 0)
            close_p = row.get('æ”¶ç›¤åƒ¹', 0)
            
            if open_p >= close_p:
                continue
                
            # æ¢ä»¶ 4: æ”¶ç›¤åƒ¹ > éå» 15 æ—¥æœ€é«˜åƒ¹
            max_15_high = row.get('Max15_High', 0)
            if pd.isna(max_15_high) or close_p <= max_15_high:
                continue

            # æ¢ä»¶ 5: æˆäº¤ç­†æ•¸ < 300
            trans_count = row.get('æˆäº¤ç­†æ•¸', 0)
            if pd.isna(trans_count) or trans_count >= 300:
                continue
                
            # æ¢ä»¶ 3: K > D
            k = row.get('K', 0)
            d = row.get('D', 0)
            
            if k <= d:
                continue
                
            final_candidates.append(row)
            
        except Exception as e:
            continue
            
    final_df = pd.DataFrame(final_candidates)
    print(f"ç¯©é¸å®Œæˆï¼Œå…± {len(final_df)} æª”ç¬¦åˆæ¢ä»¶")
    
    # 6. ç”¢å‡ºå ±è¡¨
    if not final_df.empty:
        report_path = report.generate_excel(final_df, today_date)
        
        # 7. ç™¼é€é€šçŸ¥
        if report_path:
            msg = f"ğŸ“Š è‚¡å¸‚åˆ†æå ±å‘Š ({today_date})\nç¬¦åˆç¯©é¸æ¢ä»¶: {len(final_df)} æª”"
            notifier.send_telegram_report(report_path, msg)
    else:
        print("ç„¡ç¬¦åˆæ¢ä»¶è‚¡ç¥¨ï¼Œä¸ç™¼é€å ±å‘Š")

if __name__ == "__main__":
    main()
